<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Hann</title>
    <description></description>
    <link>hannw.github.io</link>
    <atom:link href="hannw.github.io/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>How to Implement Synthetic Gradient for RNN in Tensorflow</title>
        <description>The theory of synthetic gradient for RNN, it's implications, and how to implement it in tensorflow</description>
        <pubDate>Sat, 27 Jan 2018 00:00:00 -0800</pubDate>
        <link>hannw.github.io/posts/synthetic-gradient-rnn</link>
        <guid isPermaLink="true">hannw.github.io/posts/synthetic-gradient-rnn</guid>
      </item>
    
      <item>
        <title>How to make sense of cross entropy</title>
        <description>Understanding the most used loss function in deep learning - cross entropy.</description>
        <pubDate>Sun, 16 Apr 2017 00:00:00 -0700</pubDate>
        <link>hannw.github.io/posts/cross-entropy</link>
        <guid isPermaLink="true">hannw.github.io/posts/cross-entropy</guid>
      </item>
    
      <item>
        <title>L1, L2 regularization demystified.</title>
        <description>Breaking down L1, L2 regularization.</description>
        <pubDate>Fri, 14 Apr 2017 00:00:00 -0700</pubDate>
        <link>hannw.github.io/posts/l1-l2-regularization</link>
        <guid isPermaLink="true">hannw.github.io/posts/l1-l2-regularization</guid>
      </item>
    
  </channel>
</rss>
